---
title: "The history of behavioural addictions research (according to PubMed): Part 2"
description: ""
author:
  - name: Rob Heirene
categories: [Gambling] 
date: 2023-08-25
draft: true 
---

### Data & code set-up

Just like in Part 1, I'll first load all the required packages and fonts for figures.

```{r results=FALSE, warning=FALSE, message=FALSE}
#| code-fold: true
#| code-summary: "Code: set-up"

# Install and load the groundhog package to ensure consistency of the package versions used here:
# install.packages("groundhog") # Install

library(groundhog) # Load

# List desired packages:
packages <- c('readr', # Load dataset from GitHib
              'tidyverse', # Clean, organise, and visualise data
              'gt', #  table data
              'gtExtras', # Add colours to gt tables
              'plotly', # Add interactive elements to figures
              'gganimate', # Make animated plots
              'transformr', # Needed for certain animations (dumbell lines)
              'png',# Helps render gganimate plots
              'gifski', # Helps render gganimate plots
              'rmarkdown', # Helps render gganimate plots
              'av', # render gganimate plots as videos
              'Cairo', # Anti-aliasing for the line plots (smoothing output)
              'ggtext', # make fancy labels in plots
              'sysfonts', # Special fonts for figures
              'showtext', # Special fonts for figures
              'htmlwidgets', # Make plotly plots HTML format for rendering in Quarto
              'scico', # Colour palette
              'maps', # Get map/geographic data for author locations
              'purrr', # Help unnest city and author names across papers  equally
              'stringr', # extract city names
              'viridis', # More colour palettes
              'sessioninfo') # Detailed session info for reproducibility 

# Load desired package with versions specific to project start date:
groundhog.library(packages, "2023-08-01") 

# Load new font for figures/graphs
font_add_google("Poppins", "Poppins")
font_add_google("Reem Kufi", "Reem Kufi")
showtext_auto(enable = TRUE) 


plot_theme <-  theme(plot.background = element_rect(fill = "#002B36",  color = NA), # ADDING THIS NA REMOVES BORDER AROUND PLOT ON WEBSITE
     panel.background = element_rect(fill = "#002B36"),
     text = element_text(family = "Reem Kufi", color = "#F5F7F0"),
     axis.text = element_text(color = "#F5F7F0", size = 13),
     panel.grid = element_blank(),
     plot.title = element_text(color = "#F5F7F0", size = 16),
     plot.subtitle = element_text(color = "#50B5C8", size = 12),
     plot.caption = element_text(color = "#50B5C8"))
```

Now I'll load in the dataset and do a little cleaning. Again,, I'm going to remove all publications from 2023 so that we only have data for complete years (see comments in the code chunk below for any other exclusions).

```{r results=FALSE, warning=FALSE, message=FALSE}
#| code-fold: true
#| code-summary: "Code: load dataset"

url_behav_addic_data_link <- "https://raw.githubusercontent.com/rheirene/pub-med-scape-behav-addictions/main/Data%20extraction/combined_results_clean.csv"

raw_data <- read_csv(url_behav_addic_data_link) %>%
  as_tibble()

str(raw_data)
# View(data)

# Despite my best efforts with manual searching, my explorations of this dataset in R revealed that there are a few erratums/corrigendums and one notice of retraction included in the data. Let's remove these before moving forward:
filtered_data <- raw_data %>%
  filter(str_detect(Publication_Type, "Erratum") | 
         str_detect(Publication_Type, "corrigendum") | 
         str_detect(Publication_Type, "Retraction")) %>% 
  distinct(PMID, .keep_all = TRUE)

# Let's now remove these pubs and any from 2023 so we have data for all "full" years:
data <- raw_data %>% 
  anti_join(filtered_data) %>%
    filter(Year != "2023") 

# View(data)

```

### Where do these papers come from?

I want to to visualise this information, but it's going to be quite tricky as each paper has a variable number of authors and therefore institution addresses, all of which are listed in a single (often messy) string within one column in the dataset. I'll have to separate out each author institution and then find a way to extract only the relevant information to be able to geo-locate them.

```{r warning=FALSE, message=FALSE}
#| code-fold: true
#| code-summary: "Code: Extract location data for each paper"

# ***********************The below code is almost all commented out on purpose as the process of extracting and matching city names from the author address column is so computationally taxing that it takes a long time to process.  I've left the code here so that anyone can see how I did it, but I saved the results as a .csv file and now load the data like that***********************

# as_tibble(data$Author_Address) # Take a look at how the author addresses are structured

# Okay, so we're going to need to create an ID variable for each paper (this makes the string split and a nest below work bettter than relying on titles), then split the author_address strings into separate addresses, then unnest these into new rows. 

# Whilst I'm splitting and unnesting the author address: I'm going to simultaneously do this for the authors name column.


# The un-nest doesn't seem to work well when we retain all of the columns in the dataset, so I do it with only id and institution (address) in the data, then join all of the rest of the data set to the unnested rows after this. For this to work, we need to create a dataset that has the ID variable in before splitting the string and and unnesting. Let's do that:
 data_id <-data %>%
  rowid_to_column(var = "id")

 pad_vector <- function(vec, len) {
  length(vec) <- len
  return(vec)
 }

# Now split the author and address strings and then  unnest it into multiple rows, and finally re-join with the main dataset
data_locations <- data_id %>%
    mutate(
     institution = str_split(Author_Address, ";"), # Split author address column into separate strings For each address
    author_names = str_split(Full_Author_Name, ";") # Split author name column into separate strings For each Name
  ) %>%
  # The below code matches the number of author institutions and author names where discrepancies exist, so the unnest further below works:
   mutate(
    max_length = pmax(map_int(institution, length), map_int(author_names, length)),
    institution = map2(institution, max_length, ~ pad_vector(., .y)),
    author_names = map2(author_names, max_length, ~ pad_vector(., .y))
  ) %>%
  select(id, institution, author_names) %>%
  unnest(c(institution, author_names)) %>%
  # Looking at the data at this point, there's a lot of white space around the institutions and author names. Let's remember that now:
  mutate(institution = str_trim(institution, side = "both"),
         author_names = str_trim(author_names, side = "both")) %>%
  full_join(data_id, by = "id") %>%
  # Whilst we're doing this, we'll also create a counter/number for each institution per paper
  group_by(id) %>%
  mutate(author_num = row_number()) %>%
  ungroup()
  # We can also pivot to wide format if that makes sense at any point:
  # pivot_wider(names_from = author_num,
  #             values_from = institution,
  #             names_prefix = "author_",
  #             values_fill = NA_character_)

# View(data_locations) # Looks good!

# Uncomment from below this line

# Fortunately, the "maps"  package contains a list of city names that we can use to match with our author institutions. Let's load the relevant data:
## Loading country data from package maps
data(world.cities)

 # The way the matching process works below is by picking the first match in the string, so removing all of the cities below actually leads to an increase in proper matches as the wrong matches are skipped over:
world_cities_filtered <-  world.cities %>%
  filter(!name %in% c("China", # There is a city in Mexico called China, and including this in the dataset needed to pick up any papers published in China and link them to this city!
                        "India", # Same sort of issue (City in Africa)
                        "San",  # Same sort of issue (City in Africa, again)
                        "Institut", # This appears to be act somewhere around Azerbaijan, but I think it's getting picked up as a city when in fact it just is a string in the author address referring to a university!
                       "Santa", # This is picked up as a city In Peru, when in fact  with just part of the name of the hospital
                      "God", # This is picked up as the name of a city in the Hungary, when in fact is just  part of the name of a hospital in Ireland
                      "Normal", # This is picked up as a city in the US  when in fact it's part of a university name in China
                      "Bar", # This is picked up as a city in Ukraine, when in fact it's just the name of the University in Israel
                      "Victoria", #  This leads to confusion between Victoria in Canada and the state in Australia. Easier just to remove rather than be inaccurate
                      "Cardinal",
                      "Villanueva", # This is actually a university in Spain, but it's picked up as a city in Honduras

                      "Beira", # This is picked up as a city of Mozambique, but eventually the University Hospital name in Portugal
                      "Cardinal",
                      "Young", # This is picked up as a city in Uruguay, when is just part of the name of a young adult hospital in France
          
                      "Cornwall", # Get picked up as a city in Canada and not the area of the UK
                       "George", #  A street name in the US,  confused for the South African city
                       "Imperial", #  part of a UK university name but picked up as a city in Peru
                      "Laval", # Part of a university name in Canada but gets picked up as the city in France
                      "Villa", # Part of the name of a institution in Italy, but picked up as the Estonian city.
                      "Aidu", # Part of the name of a Japanese hospital, but picked up as a Estonian city
                     "Carolina", # Part of the US state name in the data, but picked up as a city in Peurto Rico
                       "Carmel", # Get confused with the US city, but always Israel in the dataset
                              "U",#  seems like shorthand for an address in France, but has picked up as a city in Micronesia and the French city is missed
                              "Ramon",  # Part of the name of a hospital in Spain, but picked up as the city in the Philippines
                             "Fundacion", #  Part of the name of a institution in Spain, but picked up as a city in Colombia
                             "Trinidad", # Part of a institution name in Argentina, were picked up as a city in Bolivia
                             "Liege",# Picked up as a city in Belgium, but it's actually part of a name of a place in France
                             "East London", # Refers to the UK University, picked up as a city in South Africa
                             "Florida", # University name picked up as a city in Cuba
                             "Ita", # Part of the name of a institution in Finland picked up as the city in Paraguay
                     "Princeton", #  University name confused for the city in Canada
                     "Humboldt", # Confused for the Canadian city, but actually a University in Germany
                      "Alcala", # Confused for the Colombian city, but actually part of a university name in Spain)
                            "York", # UK Canada confusion. Easier to remove
                     "Union", # Typically refers to the European Union, but confuse for the US city
                      "La Rioja", # Part of a Spanish University but computer the city in Argentina
                     "Concord", # Area in Australia that ends up being linked to a US city rather
                      "Nanyang", # Part of a Singapore university name that gets linked to a city in China
                      "Patan", # Part of a Napoleon University name that gets linked to a cityin India
                      "Saint-Joseph", # University name in Lebanon on that gets linked to a city in Reunion
                     "Valencia", # University in Spain that gets linked to Venezuela
                      "Ingenio", # Institution in Spain that gets linked to the Canary Islands
                     "Lincoln", # UK university name that gets linked to the US
                     "Roma", # Italian street name that gets linked to Australia
                     "Leon", # Institution name in France forgets links to Mexico
                     "Pau", # Part of a hospital name in Spain that Gets linked to France
                     "Ilan", # Part of a university name in Israel that gets linked to Taiwan
                     "Street", #  an obvious issue. Linked to the UK incorrectly
                     "Alle",  # Incorrectly linked to Switzerland when it's an address in Denmark'Hashtag
                     "San Ignacio", # Location improved its link to Bolivia
                     "Carnot", # Street in France that gets linked to central Africa
                      "Mexico", #  country gets incorrectly linked to the Philippines city
                      "Mobile", #  Institution in Canada that gets incorrectly linked to the US
                      "Hebron", # Location in Spain gets mixed up with Palestine
                     "Liban", #  hospital in France that gets linked to Czech Republic
                     
                     "Bayonne", # Addiction clinic in France linked to the US incorrectly
                     "Apartado", # Confusion between Spain and Colombia. Better to just remove
                     "Rioja", # Appears in a few different places and can be linked to Spain or Peru
                      "Li", #  part of a university name in China can be linked to Norway incorrectly
                     "Al", # Part of the name of places in Saudi Arabia and other countries that gets picked up as a city in Norway
                     "San Agustin", # Part of the name of a place in Peru that getting linked to Mexico
                     "Asia", # A city name in the Philippines that is obviously going to give problems
                     "Jordan", #  country name acts incorrectly linked to the Philippines city
                     "Kota", # Location in Malaysia that gets linked to India incorrectly
                     "Ribera", # Part of an institution name in Spain gets linked to Italy
                     "Pilar", # Name of a Institute in Croatia that gets linked to Brazil incorrectly
                      "Greenwich", # Causes various problems due to being linked to the US and UK
                      "George Town", #In Malaysia, baguettes linked to the Cayman Islands
                     "Worth", # Should the Fort Worth in America, baguettes link to Germany
                     "Santa Lucia", # Name of a institution in Italy that gets confused at the Canary Islands
                     "Sainte Anne", # Name of an institution in France that gets confused with the city in Canada
                     "Douglas", # Part of a university name inCanada gets confused with the Isle of Man
                     "Arizona", # State name gets confused for a city in Honduras
                     "Potsdam", # In New York gets confused with Germany
                     "Kita", # In the name of an Indonesian institution that gets confused with the city in Mali
                     "Concordia", # US university name gets confused with a town in Argentina
                     "Bay", # Monterey Bay gets confused with a town in the Philippines
                     "Parana", # Part of an institution name in Brazil gets linked to Argentina
                     "Gazi", # Incorrectly gets linked to Ken year when it should be part of a name of a university in Turkey
                     "Wufeng",# incorrectly linked to China when it should be in Taiwan
                     "Loo", # Getting correctly linked to Estonia when it's actually part of a institution name in Singapore
                     "Police" # Police college accidentally linked to city in Poland
                     )) %>% 
  # A combination of city names and country names can be used to keep the city where it seems like it can be saved:
    mutate(city_country = paste0(name,", ", country.etc)) %>% 
  filter(!city_country %in% c("Sussex, Canada",# Only the UK one appears and this gets confused
                              "Milton, Canada", #  should be Milton Keynes in the UK
                              "Bathurst, Canada", # Location in Australia they get confused Canada
                              "Milton, New Zealand", #  should be Milton Keynes in the UK
                              "Orleans, France", #  incorrectly linked to France, not Canada
                              "Bergen, Norway", # teams to be linked consistently to the US,  but mistaken for Norway
                              "Penrith, UK", # Should be the Australian city near Sydney
                              "Bedford, UK", #  location in Australia gets Linked to the UK incorrectly
                              "Bedford, USA", #  location in Australia gets Linked to the US incorrectly
                              "Salt, Spain", # Should be Salt Lake City, US,  but gets picked up as the Spanish city
                              "Lancaster, USA", #  should be the UK
                              "Ho, Ghana", # Part of an address in Taiwan that's getting linked to Ghana
                              "Laguna, USA", # Should be the canary islands, surprisingly
                              "Castello, Spain", #  Italian university name
                              "Ulm, Germany", #  address in France that should always be linked to it and not germany
                              "Albert, France",
                              "Hong, Denmark",# Leads to this being picked up and said of Hong Kong
                             "Durham, USA", # Should be the UK one
                             "Brest, Belarus", # Refers to France not Belarus
                             "Warwick, USA", #  Always seems to refer to the UK university, but the Use of the US city
                             "Belmont, Canada", #  Always seems to refer to the US,  but confused for the Canadian city
                             "Beaufort, Malaysia", # Should be the American city
                             "Mackay, Australia", #  should always be the location in Taiwan
                             "Alicante, Philippines", #  should always be in Spain
                             "Malaya, Philippines", # Should be in Malaysia
                           "Claremont, Jamaica", #  Australian location that gets sent to Jamaica, incorrectly
                           
                           "Colombia, Cuba", # Get confused with the country
                           "Carlton, UK", #Street name in Canada gets confused with the UK
                           "Costa Rica, Mexico", # Obviously get complete. The country
                           "Notre Dame, Mauritius", #  actually the Australian University!
                            "Baja, Hungary", # University namely Mexico
                           "Palmerston, Australia", # Incredibly links to the northern Australian city, rather than  New Zealand
                           "Waterloo, USA" # Always the Canadian university
         )) %>% 
   group_by(name) %>%
  filter(pop == max(pop)) %>% # Okay, so this is imperfect, but when a city name is duplicated that I haven't accounted for above, this will filter to select only the one with the highest population. This is based on the assumption that papers are likely to come from more populated cities (i.e. those with universities). This may seem crude, but it solved many, many issues in the map.
  ungroup() 

# Extract just the city names so we can try and match author locations using these:
city_names_from_world <- world_cities_filtered$name

# Create a pattern of city names for matching with word boundaries:
city_names_pattern <- paste("\\b(", paste(city_names_from_world, collapse = "|"), ")\\b", sep = "")

# Extract city names using stringr (the str_exact function extracts the first complete match from a string; the arguments are the string and then the match we're looking for)
cities_of_authors <- str_extract(data_locations$institution, city_names_pattern)



# Before we join this to our dataset, let's now do the same thing for countries, using the world dataset. We could just link countries to the existing cities we identified, but this won't give us the richest overall data, as in some cases it might find a country name but no city name and vice versa.

# Extract just the Country names so we can try and match author locations using these:
country_names <- world.cities$country.etc

# Create a pattern of Country names for matching with word boundaries:
country_names_pattern <- paste("\\b(", paste(country_names, collapse = "|"), ")\\b", sep = "")

# Extract country names using stringr (the str_exact function extracts the first complete match from a string; the arguments are the string and then the match we're looking for)
countries_of_authors <- str_extract(data_locations$institution, country_names_pattern)



# Add the extracted city and country names to our dataset:
data_locations_with_city_country<- data_locations %>%
  bind_cols(cities_of_authors,
            countries_of_authors) %>%
  rename(cities_of_authors = 19,
         countries_of_authors = 20)
# Check everything looks okay:
#  select(author_names,
#         cities_of_authors,
#         countries_of_authors) %>%
#  print(n=150)

# Make the city name column consistent with paper dataset:
world_cities_filtered <- as_tibble(world_cities_filtered) %>%
  rename(cities_of_authors = name)

#Join the world.cities dataset with our paper data so we have latitude and longitude for each city:
data_locations_with_full_geo_location<-
  left_join(data_locations_with_city_country,
           world_cities_filtered,
           by = join_by(cities_of_authors) # This is done purposely, as I want to check whether the country names matched in text above match with the country names linked to the city names. Any mismatches tell us a lot about whether it got the right city are not and how I filtered out most of the problematic cities above!
           )

# Now, Save this to a CSV file because this took forever to extract the data we don't want to have to do this every time I render this page!!
write.csv(data_locations_with_full_geo_location, "posts/2023-history-of-behavioural-addictions-PubMed-part2/data_locations_with_full_geo_location.csv")

```

Phew, that was intense. It was computationally demanding to link \>40,000 author addresses to one out of every single city and country name worldwide so i've saved the dataset to Github and nowI'll load it in from there and do some cleaning.

```{r results=FALSE}

# Okay, now actually load pre-created data from Github:
url_geo_loc_data_link <- "https://raw.githubusercontent.com/rheirene/Quarto_Website/master/posts/2023-history-of-behavioural-addictions-PubMed-part2/data_locations_with_full_geo_location.csv"

data_locations_with_full_geo_location <- read_csv(url_geo_loc_data_link) %>%
  as_tibble() 

# Looking for mismatches betweencountries matched to cities I extracted and countries matched by text (as I do below) is how I spotted most of the problematic cities.

# names(data_locations_with_full_geo_location)


# Let's explore this data to see any mismatches
 data_locations_with_full_geo_location %>% 
filter(countries_of_authors != country.etc) %>% # Identify and isolate mismatches
  select(institution,
       author_names,
         cities_of_authors,
         countries_of_authors,
       country.etc) %>%
  print(n=350) # Started with several thousand
 
# Looking at the results above, it's clear we need to prioritise matched country (i.e., the one we extracted from the text) over the linked one (linked to city name from database) as mistake are rate with the matched one as it's simple text extraction, whereas the link from city to country can be fallible as there are multiple cities with the same nameand it could have matched with the wrong city.

# There are a few important caveats to the above that we will need to directly recode for accuracy:
# Georgia USA. This gets extracted as the country, but it's obviously the state in the US! Also, the city in Georgia, Athens gets links to Greece incorrectly. 
# Mongolia.  Inner Mongolia normal University appears to be in China, but gets extracted as in Mongolia 
# Mexico. The University of New Mexico often gets linked to the country Mexico when it should be the US
# Jersey. Gets linked to the small country south of the UK, instead of the University of New Jersey!
 
# There are also a few key cities that are duplicated that I didn't remove in the filtering above that will need directly linking via code to the right city and country, including Cambridge, New York, London, Oxford, Liverpool, Bristol, Reading, Columbia, Northampton, Stirling, Aberdeen and Newport

 # Check allpotential problematic locations:
 data_locations_with_full_geo_location %>%
   # filter(countries_of_authors  == "Georgia") %>% 
   # filter(countries_of_authors  == "Mongolia") %>% 
   # filter(countries_of_authors  == "Mexico") %>% 
  # filter(countries_of_authors  == "Jersey") %>% 
   # filter(countries_of_authors  == "Jersey") %>% 
   # filter(str_detect(institution, "Columbia")) %>% # Check anywhere for this one!
  #  filter(str_detect(institution, "Colombia")) %>% # Check anywhere for this one!
  # filter(str_detect(cities_of_authors, "Marietta")) %>% 
   # filter(str_detect(cities_of_authors, "Liverpool")) %>%
   # filter(str_detect(cities_of_authors, "Reading")) %>%
   # filter(str_detect(cities_of_authors, "Northampton")) %>%
   # filter(str_detect(cities_of_authors, "Stirling")) %>%
   # filter(str_detect(cities_of_authors, "Cambridge")) %>% 
 # filter(str_detect(cities_of_authors, "Aberdeen")) %>%
 # filter(str_detect(cities_of_authors, "Newport")) %>%
  filter(str_detect(cities_of_authors, "Oxford")) %>%
    select(institution,
       author_names,
         cities_of_authors,
         countries_of_authors,
       country.etc) %>%
  print(n=350)
 
data_locations_with_full_geo_location_cleaned <- 
 data_locations_with_full_geo_location %>%
  mutate(cities_of_authors = case_when(
    # Sort Georgia country/Athens city issues:
    str_detect(institution, "Georgia State") ~ "Atlanta",
    str_detect(institution, "University of Georgia") ~ "Athens",
    str_detect(institution, "Georgia College") ~ "Milledgeville",
    #  Mongolia city issues:
    str_detect(institution, "Inner Mongolia") ~ "Hothot",
    # Mexico City issues:
    str_detect(institution, "University of New Mexico") ~ "Albuquerque",
    # Jersey issues:
    str_detect(institution, "Rutgers") &
    !str_detect(institution, "Camden") &
    !str_detect(institution, "New York") ~ "New Brunswick", # this isn't perfect, but cities are often missing for Rutgers
     # Sort Columbia issues:
    str_detect(institution, "Vancouver") ~ "Vancouver",
    str_detect(institution, "Columbia University") ~ "New York",
    # Sort Colombia issues:
    str_detect(institution, "Bogota") ~ "Bogota",
    str_detect(institution, "Barranquilla") ~ "Barranquilla",
    str_detect(institution, "Pasto") ~ "Pasto",
    str_detect(institution, "Campus Robledo") ~ "Medellin",
    # Aberdeen issues:
   str_detect(institution, "Hong kong") ~ "Hong Kong",
   # Newport issues:
   str_detect(institution, "Christopher Newport University") ~ "Newport News",
    TRUE ~ as.character(cities_of_authors)  # Default if none of the above matches
  )) %>%
  mutate(countries_of_authors = case_when(
    # Sort Georgia country issues:
    str_detect(institution, "Georgia State University") ~ "USA",
    str_detect(institution, "University of Georgia") ~ "USA",
    str_detect(institution, "Georgia College") ~ "USA",
    str_detect(cities_of_authors, "Mariette") ~ "USA",
    # Mongolia country issues:
    str_detect(institution, "Inner Mongolia") ~ "China",
    # Mexico Country issues:
    str_detect(institution, "University of New Mexico") ~ "USA",
    # Jersey country issues:
    str_detect(institution, "New Jersey") ~ "USA",
    # Cambridge city issues:
    str_detect(institution, "Harvard") ~ "USA",
    str_detect(institution, "University of Cambridge") ~ "UK",
    str_detect(institution, "Cambridge Health Alliance") ~ "USA",
    str_detect(institution, "Anglia Ruskin University") ~ "UK",
    # London city issues
    str_detect(institution, "London")  &
    !str_detect(institution, "Canada") ~ "UK",
    # Sort Columbia issues:
    str_detect(institution, "University of British Columbia") ~ "Canada",
    str_detect(institution, "Columbia University") ~ "USA",
    str_detect(institution, "United States of America") ~ "USA",
    str_detect(institution, "Missouri") ~ "USA",
     str_detect(institution, "New York") ~ "USA",
    str_detect(institution, "British Columbia") ~ "Canada",
    str_detect(institution, "Chilliwack") ~ "Canada",
    # Sort Colombia issues:
     str_detect(institution, "Barranquilla") ~ "Colombia",
    # Sort Liverpool issues: 
  str_detect(institution, "John Moores") ~ "UK",
  str_detect(institution, "University of Liverpool") ~ "UK",
  str_detect(institution, "LiMRIC") ~ "UK",
  str_detect(institution, "Liverpool, England") ~ "UK",
   str_detect(institution, "Liverpool John") ~ "UK",
  # Reading issues:
  str_detect(institution, "University of Reading") ~ "UK",
   str_detect(institution, "USA") ~ "USA",
  str_detect(institution, "United States") ~ "USA",
  # Northampton issues:
  str_detect(institution, "University of Northampton") ~ "UK",
  str_detect(institution, "Gemini Research") ~ "USA",
  # Sterling issues:
   str_detect(institution, "Australia") ~ "Australia",
   # Aberdeen issues:
   str_detect(institution, "Hong kong") ~ "China",
     # Newport issues:
   str_detect(institution, "Christopher Newport University") ~ "USA",
  # Oxford issues:
   str_detect(institution, "University of Oxford") ~ "UK", 
  str_detect(institution, "Oxford, UK") ~ "UK", 
  str_detect(institution, "Oxford Centre for") ~ "UK", 
    TRUE ~ as.character(countries_of_authors)  # Default if none of the above matches
  ))
 
# Now look to see what#s left and see if it matters now if we assume our created city and country names are correct and the link is an error:
 data_locations_with_full_geo_location_cleaned %>% 
filter(countries_of_authors != country.etc) %>% # Identify and isolate mismatches
  select(institution,
       author_names,
         cities_of_authors,
         countries_of_authors,
       country.etc) %>%
  print(n = 340)

 
# need to try and linkj long and lat to the combination of city and country where possible



 # Other problematic  Cities we need to directly code:
 # Athens
 # Nottingham
```

```{r}
#| code-fold: true
#| code-summary: "Code: Create interactive map of papers"
#| fig-align: center

# Load world map data but filter out Antarctica as we don't have any values/papers for this region and it just takes up space on the map:
world_map <- map_data("world") %>% filter(region != "Antarctica")

# Join the world map data with our paper data:
data_locations_with_full_geo_location_WORLD<- left_join(data_locations_with_full_geo_location, world_map) %>%
  # Tidy the behavioural addiction labels:
    mutate(Label = str_replace_all(Label, "_", " ") %>%
                 str_to_title())

# Wrangle data for plot:
data_locations_with_full_geo_location_WORLD_city_aggregate<- data_locations_with_full_geo_location_WORLD %>%
  # Calculate the unique number of papers that can be linked to each city:
   group_by(cities_of_authors) %>%
  summarise(
    num_papers = n_distinct(PMID),
    lat = first(lat),   # Retain the first value of latitude for the city
    long = first(long),  # Retain the first value of longitude for the city
    group = first(group) # Retain the group value from the world map dataset
  ) %>%
  filter(!is.na(cities_of_authors)) %>% # Remove rows where we don't have a city
    arrange(desc(num_papers)) %>%    # Just for easier viewing
  ungroup() #  Doing this usually prevents issues later on!

# It takes quite a long time to produce the interactive plot, so instead of waiting each time I run this script I'm just loading in the version I created earlier. Comment out all of the code below to create the plot.


# # Create plot:
# all_publications_map <- ggplot(world_map, aes(x = long, y = lat, group = group)) +
#   geom_polygon(fill="#289998", colour = "#289998") +
#    geom_point(data = data_locations_with_full_geo_location_WORLD_city_aggregate,
#               aes(x = long, y = lat,
#               size = sqrt(num_papers),
#               text = paste("City:", cities_of_authors, "\nNo. of publications:", num_papers)),
#               colour = "#50B5C8",
#               fill = "#F5F7F0",
#               alpha = 1,
#               shape = 21) +  # Use shape 21 for filled circles
#   scale_size_continuous(guide="none") +
#   scale_x_continuous(expand = c(.001, .001)) +
#   # scale_y_continuous(expand = c(.001, .001)) +
#   plot_theme +
#   theme(
#     axis.text = element_blank(),
#     axis.title = element_blank()) +
#   labs(
#     title = "Institutions of authors publishing behavioural addictions research",
#     subtitle = "Each circle represents a city and its size corresponds to the number of papers can be linked to it",
#     caption = "Rob Heirene (@rheirene)"
#   )
# 
# # Save this now as a basic plot:
# ggsave("posts/2023-history-of-behavioural-addictions-PubMed-part2/all_publications_map.svg",
#        plot = all_publications_map,
#        width = 9,
#        height = 6,
#        dpi = 600)
# 
# 
# # We're going to turn this into an interactive plot now using ggplotly, but this removes some of our existing theme settings, especially the fonts. The standard way of changing the font in ggplotly doesn't seem to work for me, and it seems like other people having the same issue. I found this workaround online (https://github.com/plotly/plotly.R/issues/2117) which I now use below to load and use the correct font once this becomes a ggplotly:
# 
# # Get the URL for the "Reem Kufi" font from Google Fonts:
# reem_kufi_file <- showtextdb::google_fonts("Reem Kufi")$regular_url
# 
# # Create custom CSS:
# reem_kufi_css <- paste0(
#   "<style type = 'text/css'>",
#     "@font-face { ",
#       "font-family: 'Reem Kufi'; ",
#       "src: url('", reem_kufi_file, "'); ",
#     "}",
#   "</style>"
# )
# 
# # Convert static plot to ggplotly format and adjust theme settings where required:
#  all_publications_map_ggplotly <-ggplotly(all_publications_map,
#                                               tooltip = 'text') %>%
#   hide_legend() %>%
#   plotly::layout(annotations =
#  list(x = 1, y = -0.1, text = "Rob Heirene (@rheirene)",
#       showarrow = F, xref='paper', yref='paper',
#       xanchor='right', yanchor='auto', xshift=0, yshift=25,
#       font=list(size=12, color="#50B5C8")),
#        margin = list(t = 70), # Increase top margin
#                  font = list(family = "Reem Kufi"),
#                  title = list(x = 0, y = 0.945),
#     hoverlabel = list(font = list(family = "Reem Kufi")
# ))
# 
# # Add the CSS as a dependency for the plotly plot:
# all_publications_map_ggplotly$dependencies <- c(
#   all_publications_map_ggplotly$dependencies,
#   list(
#     htmltools::htmlDependency(
#       name = "reem-kufi-font",
#       version = "0",
#       src = "",
#       head = reem_kufi_css)))
# 
# # Display plot:
# saveWidget(all_publications_map_ggplotly, 'posts/2023-history-of-behavioural-addictions-PubMed-part2/all_pubs_map.html')
```

```{=html}
<iframe src="all_pubs_map.html" class="fade-inhtml" width="100%" height="600" style="border:none;"></iframe>
```
Well, that looks nice. I used the `ggplotly` package to make the map interactive so you can zoom into any area and hover over the circles to see which city is represented and how many papers can be linked to it.

::: {.callout-tip appearance="minimal" icon="false"}
## Spot an error in the map?

Trying to match city names to author institutions listed in the data has taught me that there are a lot of duplicated/triplicated/quadruplicated (not sure if that's even a word) city names throughout the world. This sometimes means that the author institutions were linked to the wrong city when I first ran this. I've tried to fix all of these errors (some manually, some using some quick workarounds), but if you spot an error like this then please do let me know!
:::

L

```{r}
#| code-fold: true
#| code-summary: "Code: Create animated map of papers"
#| fig-align: center

# It takes quite a long time to produce the animated plot, so instead of waiting each time I run this script I'm just loading in the version I created earlier. Comment all of the code below to Cceate the plot.


# Wrangle data for plot:
data_locations_with_full_geo_location_WORLD_city_label_aggregate<- data_locations_with_full_geo_location_WORLD %>%
 left_join(world_map) %>%
   # Calculate the unique number of papers PER ADDICTION that can be linked to each city:
   group_by(cities_of_authors,Label) %>%
  summarise(
    num_papers = n_distinct(PMID),
    lat = first(lat),   # Retain the first value of latitude for the city
    long = first(long),  # Retain the first value of longitude for the city
    group = first(group) # Retain the group value from the world map dataset
  ) %>%
  filter(!is.na(cities_of_authors)) %>% # Remove rows where we can't get the city
    arrange(desc(num_papers)) %>%  # Just for easier viewing
   # Tidy the behavioural addiction labels:
    mutate(Label = str_replace_all(Label, "_", " ") %>%
                 str_to_title()) %>%
  # Add Categories for behavioural addictions:
    mutate(labels_filter = case_when(Label == "Gambling" ~ "Gambling addiction",
                                       Label == "Gaming" ~ "Gaming addiction",
                                       Label == "Smart Phone" ~ "Smart Phone addiction",
                                       Label == "Exercise" ~ "Exercise addiction",
                                       Label == "Social Media" ~ "Social Media addiction",
                                       Label == "Tanning" |
                                       Label == "Selfie" |
                                       Label == "Crime" |
                                       Label == "Dance" |
                                       Label == "Joyriding" |
                                       Label == "Polysurgical" |
                                       Label == "Death" |
                                         Label == "Near Death" |
                                         Label == "Fortune Telling" |
                                         Label == "Love"
                                         ~ "The more obscure \"addiction\"",
                                       TRUE ~ "REMOVE")) %>%
  filter(labels_filter != "REMOVE")  %>%
  mutate(labels_filter = as.factor(labels_filter)) %>%
  ungroup()



# Now we need to create descriptive labels to appear with each addiction:
# Before proceeding, let's create a simple dataset to use that contains our  behavioural addiction categories that we can use for grouping:

location_grouping_data<- data_locations_with_full_geo_location_WORLD %>% # We need to use the earlier dataset and recreate our grouping labels, as in the dataset we created above we removed papers we couldn't locate them/ get a city
  # Add Categories for behavioural addictions:
    mutate(labels_filter = case_when(Label == "Gambling" ~ "Gambling addiction",
                                       Label == "Gaming" ~ "Gaming addiction",
                                       Label == "Smart Phone" ~ "Smart Phone addiction",
                                       Label == "Exercise" ~ "Exercise addiction",
                                       Label == "Social Media" ~ "Social Media addiction",
                                       Label == "Tanning" |
                                       Label == "Selfie" |
                                       Label == "Crime" |
                                       Label == "Dance" |
                                       Label == "Joyriding" |
                                       Label == "Polysurgical" |
                                       Label == "Death" |
                                         Label == "Near Death" |
                                         Label == "Fortune Telling" |
                                         Label == "Love"
                                         ~ "The more obscure \"addictions\"",
                                       TRUE ~ "REMOVE"))

# First create a dataset that tells us the number of **papers per addiction**:
location_grouping_data %>%
  group_by(labels_filter) %>% 
  summarise(
    papers_per_addiction = n_distinct(PMID),
    cities_per_addiction = n_distinct(cities_of_authors),
    countries_per_addiction = n_distinct(country.etc)
    ) %>%
 mutate(description = paste(papers_per_addiction, "unique papers"
                                ))


   mutate(gambling_addiction = case_when(labels_filter == "Gambling addiction" ~ sprintf("1961  \nFirst available study: \n\"Compulsive gambling\""),
                               TRUE ~ "")) %>%
    
     
# Get palette colors:
num_labels <- length(unique(data_locations_with_full_geo_location_WORLD_city_label_aggregate$labels_filter))
palette


colors_viridis<- viridis(n = length(unique(data_locations_with_full_geo_location_WORLD_city_label_aggregate$labels_filter)), option = "plasma", direction = -1)
          
labels<- unique(data_locations_with_full_geo_location_WORLD_city_label_aggregate$labels_filter)

color_map_df <- tibble(
  label = labels,
  color = colors_viridis
)

color_map <- setNames(color_map_df$color, color_map_df$label)


# Plot data:
filtered_publications_map <- ggplot(world_map, aes(x = long, y = lat, group = group)) +
  geom_polygon(fill = "#289998", colour = "#289998") +
  geom_point(data = data_locations_with_full_geo_location_WORLD_city_label_aggregate,
             aes(x = long, y = lat,
                 size = sqrt(num_papers),
                  colour = labels_filter,
                 fill = labels_filter),
             alpha = 1,
             shape = 21) +
  # Removal guides
  scale_size_continuous(guide = "none") +
  scale_color_viridis(discrete = TRUE, option = "plasma", guide = FALSE, direction = -1)+
  scale_fill_viridis(discrete = TRUE, option = "plasma", guide = FALSE, direction = -1) +
  # scale_fill_manual(values = palette_colors, guide = FALSE) +
  # scale_color_manual(values = palette_colors,
  #                       # rep("#F5F7F0",num_labels),
  #                     guide = FALSE) +
  # guides(fill = "none", color = "none") +
  scale_x_continuous(expand = c(0.001, 0.001)) +
  scale_y_continuous(expand = c(0.001, 0.001)) +
  plot_theme +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
     plot.title = element_text(margin = margin(b = 20))
    ) +
  labs(
    title = "{closest_state} papers",
    caption = "Rob Heirene (@rheirene)"
  ) +
  transition_states( ### NOT FILTER!
     labels_filter,
     transition_length = 2,
     state_length = 6,
     wrap = FALSE
   ) +
  enter_fade() +
  exit_fade()



# Animate plot in GIF format:
animate(filtered_publications_map,
        fps = 20,
        end_pause = 70,
        duration = 30,
        width = 800, height = 540,
        type = "cairo")

# The more obscure addictions referred to include turning, selfie, crime, dance, joyriding, polysurgical,  death, near death, fortune telling, and love addictions.
```

```{r include=FALSE}
# Save GIF:
# anim_save("posts/2023-history-of-behavioural-addictions-PubMed-part2/filtered_publications_map.gif", animation =  last_animation())
```

![](filtered_publications_map.gif){fig-align="center"}

### Where are these published?

```{r warning=FALSE, message=FALSE}
#| code-fold: true
#| code-summary: "Code: Create sankey plot of paper destinations"
#| fig-align: center

# Wrangle data for plot:
sankey_data<- data %>%
  distinct(PMID, .keep_all = TRUE) %>% 
    mutate(Label = str_replace_all(Label, "_", " ") %>%
                 str_to_title()) %>% 
    mutate(Behavioural_addiction = case_when(Label == "Tanning" |
                                       Label == "Selfie" |
                                       Label == "Crime" |
                                       Label == "Dance" |
                                       Label == "Joyriding" |
                                       Label == "Polysurgical" |
                                       Label == "Death" |
                                         Label == "Near Death" |
                                         Label == "Fortune Telling" |
                                         Label == "Love"
                                         ~ "More obscure \"addictions\"",
                                     TRUE ~ Label))
                                     
```

::: {.callout-tip collapse="true" appearance="minimal" icon="false"}
## Expand for session information

```{r}
#| code-fold: true
#| code-summary: "Code: Get session info"

session_info(pkgs = "attached")
```
:::

------------------------------------------------------------------------

```{=html}
<script src="https://giscus.app/client.js"
        data-repo="rheirene/Quarto_Website"
        data-repo-id="R_kgDOJ0d4fA"
        data-category-id="DIC_kwDOJ0d4fM4CXv7I"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="dark_dimmed"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script
```
